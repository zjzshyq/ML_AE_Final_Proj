---
title: "Analysis of User Preferences between AI-generated and Hand-drawn Artwork: A Case Study of pixiv.net"
author: 'Yiqing Hu, Rahila Mammadova Huseynova'
date: today
date-format: short
output: html_document
format:
  html:
    toc: true
    toc-depth: 2
theme:
  dark: superhero
  light: flatly
number-sections: true
title-block-banner: true
bibliography: bibliography.bib
csl: ieee.csl
---

# Abstract
The emergence of AI drawing models, such as Stable-Diffusion (SD) and Midjourney, has led to a significant influx of AI-generated images in the online art community. In this study, we collected daily rankings of the top 50 AI-generated images and hand-drawn artwork from [pixiv.net](http://pixiv.net). Our objective was to explore the factors/variables influencing the ranking of these images and examine the preferences of ordinary users towards AI-generated images versus hand-drawn artwork. The findings from this study will contribute to a better understanding of the impact of AI-generated artwork on user preferences and provide insights for the development of AI-assisted creative platforms.

References Test<br/>
dasfasdfas[@EconomicsChatGPT]<br/>
dasdasdsa[@AIThemedCryptocurrencies]

```{r echo=FALSE, message = FALSE}
#library("LogisticDx")
#library("ucminf")
#library("aod")

library("ordinal") #clm
library(mlogit) # mprobit
library(car) #Anova
library(dplyr)
library(knitr) # for printcl a table
library('MASS') # polr
library("oglmx") # ologit.reg
library("pscl") # pR2
library('lmtest') # coeftest, lrtest
library("brant") # brant( Brant's test)
library('performance') # r2_mckelvey
library("BaylorEdPsych") # PseudoR2
library("generalhoslem") # lipsitz, logitgof(Hosmer-Lemeshow), pulkrob(Pulkstenis-Robinson)

source("ome.R")
Sys.setenv(LANG = "en")
options(scipen=100)
setwd('/Users/huyiqing/PycharmProjects/UW_lab/ML_Project/ae')
```

# Data
This study utilizes data collected from [pixiv.net](http://pixiv.net), a popular platform for painters to share their artwork, to investigate the impact of AI-generated artworks on user-generated content. Starting from November of the previous year, the platform has witnessed a continuous influx of AI-generated works. The dataset comprises information such as tags, Views, Likes, Bookmarks, and Comments for the Top 50 artworks or pictures each day, spanning from October 31, 2022, to May 15, 2023.

```{r}
pixiv <- read.csv('../data/pixiv_tops_lm.csv',header=TRUE, sep=",")
pixiv$rank <- as.integer((pixiv$rank-1) / 10)+1
pixiv$is_comic <- as.factor(pixiv$is_comic)
pixiv$is_Genshin <- as.factor(pixiv$is_Genshin)
pixiv$is_Honkai <- as.factor(pixiv$is_Honkai)
pixiv$views <-pixiv$views/1000 
pixiv$like_rate2 <- pixiv$like_rate^2
pixiv$mark_rate2 <- pixiv$mark_rate^2
# pixiv$views <- scale(pixiv$views)
```

## Samples

```{r}
ai <- pixiv[pixiv$is_ai == 1, ]
man <- pixiv[pixiv$is_ai == 0, ]
```

Number of all samples: `r nrow(pixiv)` <br/>
Number of samples of AI-generated artworks: `r nrow(ai)` <br/>
Number of samples of Hand-drawn Artworks: `r nrow(man)` <br/>

## Parameters

```{r echo=FALSE}
column_names <- names(pixiv)
column_types <- sapply(pixiv, class)
desc <- c('artworkpage id','date of being top50', 
          'ratio of liked amount of viewed amount',
          'ratio of bookmarked number of viewed number', 'whether the artwork is comic',
          'whether the artwork is generated by AI', 
          'whether the artwork is about Genshin', 'whether the artwork is about Honkai',
          'comment amount', 'viewed amount in thousand', 'dependent variable', 
          'how many times being top50 for the same artwork', 
          'date difference between created and being top', 'power of like_rate',
          'power of mark_rate')

df_info <- data.frame(Variable = as.character(column_names), 
                      Type = as.character(column_types), 
                      Description=as.character(desc))
kable(df_info)
```

# Model Varification
## Covariates and Model Selection

our research focuses on analyzing the influence of different independent variables on the rankings in the daily top 50 list on pixiv.net. Our objective is to develop an evaluation model that effectively captures the factors affecting the rankings.

The granularity of the rankings, ranging from 1 to 50, is excessively detailed for our analysis. To address this issue, we have categorized the rankings into five levels by dividing the range equally. The formula is below:

$$
\text{tier} = \left\lfloor \frac{{\text{{rank}} - 1}}{{10}} \right\rfloor + 1
$$

This categorized rank will serve as our dependent variable, enabling us to better understand the impact of the independent variables on the rankings.

Given that the categorized rank is an ordered, continuous, and discrete variable with five levels, employing an ordered choice model is a suitable approach. Therefore, we will utilize both the ordered logit and ordered probit models for our subsequent analysis, allowing us to effectively examine the relationships between the independent variables and the categorized rankings.

The logit model in R for our task is below.

```{r, message = FALSE}
tier<-as.factor(ai$rank)
logit_ai <- polr(tier~like_rate+mark_rate
                  +is_comic+is_Genshin+is_Honkai
                  +comments+top_cnt+date_diff_day
                  +views
                 ,data=ai)
```

## Goodness-of-fit tests
### Hosmer-Lemeshow and Lipsitz tests
the H0 of Lipsitz and logitgof is the form of our model is appropriate. If one of them is un-appropriate. we say the model has a problem, we need to correct the model. Only if both test get the model is appropriate, then we can say the model is appropriate.

```{r}
lipsitz.test(logit_ai) 
```
p-value is 0.0000002942 < 5%, can't reject the H0, so the form of our model has a problem.

```{r}
logitgof(tier, fitted(logit_ai), g=5, ord = TRUE) # Lemeshow
```
p-value is 0.00007257 < 5%, can't reject the H0, so the form of our model has a problem.

### Pulkstenis-Robinson tests
Only if we have dummy variable, we can use robinson test. Our model has three  dummy variables which are "is_comic",'is_Genshin' and 'is_Honkai', so it is better to use Robinson test instead of Hosmer-Lemeshow and Lipsitz.

Because our prof and the doc do not mention the null hypothesises of these two methods, so I asked ChatGPT: 

pulkrob.chisq: The null hypothesis is that there is no significant departure from the expected frequencies in the observed data based on the ordinal logistic regression model. In other words, the model fits the observed data well, and there is no evidence of lack of fit.

pulkrob.deviance: The null hypothesis is that the simpler model, which is usually the null or baseline model, provides an equally good fit to the data as the more complex model. In other words, the additional predictors in the more complex model do not significantly improve the model fit.

```{r warning=FALSE}
pulkrob.chisq(logit_ai, c("is_comic",'is_Genshin', 'is_Honkai'))
pulkrob.deviance(logit_ai, c("is_comic",'is_Genshin', 'is_Honkai'))
```
Base on the null hypothesis ChatGPT gives us: we reject the H0 of Pulkstenis-Robinson chi-squared test with p-value equals to 0.03315 < 5%, means the model doesn't fit the observed data well. We reject the H0 of Pulkstenis-Robinson deviance test with p-value equals to 0.01776 < 5%, means the additional predictors in the more complex model significantly improve the model fit.

From the results of Goodness-of-fit tests, we notice that the the model for our task is not appropriate. So we remove the parameter of 'views' to check Goodness-of-fit.

```{r warning=FALSE}
logit_ai <- polr(tier~like_rate+mark_rate
                  +is_comic+is_Genshin+is_Honkai
                  +comments+top_cnt+date_diff_day
                  , data=ai)
pulkrob.chisq(logit_ai, c("is_comic",'is_Genshin', 'is_Honkai'))
pulkrob.deviance(logit_ai, c("is_comic",'is_Genshin', 'is_Honkai'))
```
Now the p-value of chi-squared and deviance tests of Pulkstenis-Robinso are all larger than 5%, so we can not reject the H0 any more, so we can get the conclusion that the model without 'views' is appropriate. 

## Odds Assumption Test
### Brant's test 

This test is to verify the proportional add assumption, the function works with polr model results. This test concludes which variable is connected to the rejection of a test. Brant's test's H0 is Parallel Regression Assumption holds.

```{r, message=FALSE, warning=FALSE}
brant(logit_ai)
```
we should focus on the first line - Omnibus, it contains test statistic for the test and the p-value. Test statistic(X2) is 67.41 and probability(p-value) is 0, so we have to reject the null hypothesis, so Parallel Regression Assumption doesn't hold, so our model is not fine. so we shouldn't use ordered logit model. The variables with the probability higher than 5% indicate if it is connected to the rejection of a test. So instead of using ordered logit model, we should choose ordered profit model which does not have the proportional odds assumption.

```{r message = FALSE, warning=FALSE}
ai$tier<-as.factor(ai$rank)
probit_ai <- clm(tier~like_rate+mark_rate
                  +is_comic+is_Genshin+is_Honkai
                  +comments+top_cnt+date_diff_day
                  , data=ai, link=c('probit'))
```

## R2 statistics

```{r}
pR2(logit_ai) 
pR2(probit_ai)
```

R2 for logit model cannot be explained alone, for example, the value of McFadden must be compared with other models to be interpreted. McFadden R2 of probit model is 0.0823 comparing the McFadden R2 of logit which is0.0872, the McFadden R2 of probit is lower than logit, which means probit model is more suitable in this situation.

```{r warning=FALSE}
pulkrob.chisq(probit_ai, c("is_comic",'is_Genshin', 'is_Honkai'))
pulkrob.deviance(probit_ai, c("is_comic",'is_Genshin', 'is_Honkai'))
```
Of course, the goodness-of-fit tests of Pulkstenis-Robinson also give the prove that the probit model is suitable.

## man made
Same processes for the samples of man-made artworks,

```{r warning=FALSE, message=FALSE}
man$tier<-as.factor(man$rank)
probit_man <- clm(tier~like_rate+mark_rate
                  +is_comic+is_Genshin+is_Honkai
                  +top_cnt+date_diff_day+views+comments
                  , data=man, link=c('probit'))
pulkrob.chisq(probit_man, c("is_comic",'is_Genshin', 'is_Honkai'))
pulkrob.deviance(probit_man, c("is_comic",'is_Genshin', 'is_Honkai'))
```
We cannot pass the test of goodness-fit with p-value < 5%

```{r warning=FALSE, message=FALSE}
man$like_rate3 <- man$like_rate^3
man$mark_rate3 <- man$mark_rate^3
probit_man <- clm(tier~like_rate+mark_rate
                  +like_rate2+mark_rate2
                  +mark_rate3
                  +is_comic+is_Genshin+is_Honkai
                  +top_cnt+date_diff_day+views
                  , data=man, link=c('probit'))
```

```{r warning=FALSE, message=FALSE}
pulkrob.chisq(probit_man, c("is_comic",'is_Genshin', 'is_Honkai'))
pulkrob.deviance(probit_man, c("is_comic",'is_Genshin', 'is_Honkai'))
```

After removing the parameters of 'comments' and adding like_rate2,mark_rate2, mark_rate3, our model for man-made model works.

## Model Selection
### Likelihood Ratio Test

```{r warning=FALSE}
probit_ai_restricted <- clm(as.factor(tier)~1, data=ai)
lrtest(probit_ai, probit_ai_restricted)
```

The restricted model with constant only:as.factor(tier)~1, the p-value of the likelihood ratio test statistic associated with test statistics is almost 0 < 5%, we have to reject the H0: beta1=beta2=0 (which is the condition of restriction), so they jointly significant. so we should choose unrestricted model.

### Test for variables to their powers

```{r warning=FALSE}
probit_ai_power <- clm(tier ~ like_rate+mark_rate
                  +is_comic+is_Genshin+is_Honkai
                  +comments+top_cnt+date_diff_day
                  +like_rate2+mark_rate2, data = ai, link=c('probit'))
anova(probit_ai, probit_ai_power)
```

p-value equals to 0.00012 < 5%, we have to reject the null hypothesis which is the power of beta of like_rate is 0 and beta power of mark_rate is 0,in other words, two models are equal, so these two models are significantly different, so the model probit_ai without 'is_Honkai1' and  powers of like_rate and mark_rate would be better than the one without powers.

### Variables Selection
general-to-specific method to variables selection for AI model.

```{r}
coeftest(probit_ai_power)
```

We find the p-value of 'like_rate2' and 'is_Honkai1' are lower than 5%, these two parameters are insignificant for the model, so we will deal with the the process of general-to-specific method for them.

```{r}
probit_ai_honkai <- clm(tier ~ like_rate+mark_rate
                  +is_comic+is_Genshin
                  +comments+top_cnt+date_diff_day
                  +like_rate2+mark_rate2
                  , data = ai, link=c('probit'))
anova(probit_ai_power, probit_ai_honkai)
```

p-value=0.24>0.05, we can't reject the null hypothesis, so two model is the same, then we can choose a better on with less parameters which is the one without variable is_Honkai.

```{r}
probit_ai_honkai_liked2 <- clm(tier ~ like_rate+mark_rate
                  +is_comic+is_Genshin
                  +comments+top_cnt+date_diff_day
                  +mark_rate2, data = ai, link=c('probit'))
anova(probit_ai_honkai, probit_ai_honkai_liked2)
```

p-value=0.24>0.05, we can't reject the null hypothesis, so two model is the same, then we can choose a better on with less parameters which is the one without variable 'like_rate2'

```{r}
coeftest(probit_ai_honkai_liked2)
```

```{r}
pulkrob.chisq(probit_ai_honkai_liked2, c("is_comic",'is_Genshin', 'is_Honkai'))
pulkrob.deviance(probit_ai_honkai_liked2, c("is_comic",'is_Genshin', 'is_Honkai'))
```

After checking the result of coef-test and the goodness-of-fit rest, all parameters are significant and model is fine now.

## man sample

we deal with the sample of man-made in the same processes

```{r warning=FALSE}
probit_man_opt <- clm(tier~like_rate
                  +mark_rate2
                  +mark_rate3
                  +is_comic+is_Honkai
                  +top_cnt+date_diff_day+views
                  , data=man, link=c('probit'))
pulkrob.chisq(probit_man_opt, c("is_comic", 'is_Honkai'))
pulkrob.deviance(probit_man_opt, c("is_comic", 'is_Honkai'))
coeftest(probit_man_opt)
```

# Model Estimating
## Comparation

```{r warning=FALSE, message=FALSE}
probit_ai <- ologit.reg(tier~like_rate+mark_rate
                  +is_comic+is_Genshin
                  +comments+top_cnt+date_diff_day
                  +like_rate2
                  ,data=ai)
summary(probit_ai)
```

We do not need to interpreter Threshold Parameters, the Estimate is the one we should focus on. 

Whenever the variable like_rate increases, the probability for the rank tier-1 decreases,and tier-5 increases. 

```{r warning=FALSE, message=FALSE}
probit_man <- ologit.reg(tier~like_rate
                  +mark_rate2
                  +mark_rate3
                  +is_comic+is_Honkai
                  +top_cnt+date_diff_day+views
                  ,data=man)
summary(probit_man)
```

## Marginal Effects
We will analysis the Marginal Effects for AI-generated artworks

```{r warning=FALSE}
margins.oglmx(probit_ai)
```

In the situation of Outcome==1 which is tier 1 in the Top, artwork about Genshin has higher probability than the artwork about other topics by 2.57407 percentage points.
Additional thousands units of views or exposure would increase the probability of being tier 1 artwork in the Top by 0.456918 percentage points.

# Summary

# References
::: {#refs}
:::



